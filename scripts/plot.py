'''The `plot.py` script is a Python utility designed to visualize performance
analysis results generated by the Simple Runtime Analyzer C++ library.'''

import sys
import os
import csv
import json
from pathlib import Path
from typing import Tuple, List, Dict, Any
import matplotlib
import matplotlib.pyplot as plt
matplotlib.use('QtAgg')


# Global style configuration
plt.style.use('default')
plt.rcParams.update({
    'figure.facecolor': '#0A0A0A',    # General background
    'axes.facecolor': '#111111',      # Dark grid background
    'axes.edgecolor': '#333333',      # Axes edges
    'axes.labelcolor': '#FFFFFF',     # White labels
    'text.color': '#FFFFFF',          # White text
    'xtick.color': '#FFFFFF',         # White X-axis markers
    'ytick.color': '#FFFFFF',         # White Y-axis markers
    'grid.color': '#38393b',          # Grid color
    'grid.alpha': 0.8,                # Grid transparency
    'legend.facecolor': '#111111',    # Legend background
    'legend.edgecolor': '#333333',    # Legend border
    'legend.labelcolor': '#FFFFFF'    # Legend text
})

# Color palette for multiple datasets
COLOR_PALETTE = [
    '#FF6B00',  # orange (first dataset)
    '#6A9DFF',  # blue
    '#6AFF8E',  # green
    '#C86AFF',  # purple
    '#FF6AC8',  # pink
    '#6AFFF0',  # cyan
    '#FFD46A',  # yellow
    '#FF8E6A',  # coral
    '#B86AFF',  # lavender
    '#6AFFB8',  # mint
]


def read_csv(file_path: Path) -> Tuple[List[int], List[float], str]:
    """Read data from a CSV file."""
    sizes, times = [], []
    unit = "units"

    try:
        with open(file_path, 'r', newline='', encoding='utf-8') as f:
            # Try to detect delimiter
            sample = f.read(1024)
            f.seek(0)
            sniffer = csv.Sniffer()
            dialect = sniffer.sniff(sample)

            reader = csv.DictReader(f, delimiter=dialect.delimiter)

            if not reader.fieldnames:
                print(
                    f"‚ùå Error: CSV file '{file_path}' has no headers or is empty")
                return sizes, times, unit

            required_fields = ['sample_size', 'time_value']
            if not all(field in reader.fieldnames for field in required_fields):
                print(
                    f"‚ùå Error: CSV file '{file_path}' missing required columns. Found: {reader.fieldnames}")
                return sizes, times, unit

            row_count = 0
            for row in reader:
                row_count += 1
                try:
                    size = int(row.get('sample_size', 0))
                    time = float(row.get('time_value', 0.0))
                    unit = row.get('time_unit', unit)

                    if size <= 0 or time < 0:
                        print(
                            f"‚ö†Ô∏è Warning: Invalid data in row {row_count} of {file_path}: size={size}, time={time}")
                        continue

                    sizes.append(size)
                    times.append(time)
                except (ValueError, TypeError) as e:
                    print(
                        f"‚ö†Ô∏è Skipping row {row_count} in {file_path} due to error: {e}")
                    continue

            if row_count == 0:
                print(
                    f"‚ö†Ô∏è Warning: CSV file '{file_path}' contains no data rows")

    except Exception as e:
        print(f"‚ùå Error reading CSV file '{file_path}': {e}")
        return sizes, times, unit

    return sizes, times, unit


def read_json(file_path: Path) -> Tuple[List[int], List[float], str]:
    """Read data from a JSON file."""
    sizes, times = [], []
    unit = "units"

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        print(f"‚ùå JSON decode error in '{file_path}': {e}")
        return sizes, times, unit
    except Exception as e:
        print(f"‚ùå Error reading JSON file '{file_path}': {e}")
        return sizes, times, unit

    if not isinstance(data, list):
        print(
            f"‚ùå Error: JSON file '{file_path}' should contain a list of objects")
        return sizes, times, unit

    entry_count = 0
    for entry in data:
        entry_count += 1
        try:
            if not isinstance(entry, dict):
                print(
                    f"‚ö†Ô∏è Skipping non-dictionary entry {entry_count} in {file_path}")
                continue

            size = int(entry.get('sample_size', 0))
            time = float(entry.get('time_value', 0.0))
            unit = entry.get('time_unit', unit)

            if size <= 0 or time < 0:
                print(
                    f"‚ö†Ô∏è Warning: Invalid data in entry {entry_count} of {file_path}: size={size}, time={time}")
                continue

            sizes.append(size)
            times.append(time)
        except (ValueError, TypeError) as e:
            print(
                f"‚ö†Ô∏è Skipping entry {entry_count} in {file_path} due to error: {e}")
            continue

    if entry_count == 0:
        print(f"‚ö†Ô∏è Warning: JSON file '{file_path}' contains no valid entries")

    return sizes, times, unit


def read_data(file_path: Path) -> Tuple[List[int], List[float], str, str]:
    """Read data from CSV or JSON file based on extension."""
    ext = file_path.suffix.lower()

    if ext == '.csv':
        sizes, times, unit = read_csv(file_path)
    elif ext == '.json':
        sizes, times, unit = read_json(file_path)
    else:
        raise ValueError(f"‚ùå Unsupported file extension: {ext}")

    return sizes, times, unit, file_path.stem


def validate_data(sizes: List[int], times: List[float], filename: str) -> bool:
    """Validate the integrity of the data."""
    if len(sizes) != len(times):
        print(
            f"‚ùå Error: Mismatched data length in {filename} (sizes: {len(sizes)}, times: {len(times)})")
        return False

    if len(sizes) == 0:
        print(f"‚ùå Error: No valid data found in {filename}")
        return False

    # Check for monotonic increasing sample sizes
    if sorted(sizes) != sizes:
        print(
            f"‚ö†Ô∏è Warning: Sample sizes in {filename} are not sorted. Sorting will be applied.")
        # We'll sort later during plotting

    return True


def plot_metrics(
    datasets: List[Dict[str, Any]],
    output_path: Path
) -> None:
    """Generate and save a professional metrics plot with multiple datasets."""
    if not datasets:
        print("‚ùå Error: No valid datasets to plot")
        return

    fig, ax = plt.subplots(figsize=(12, 7))

    # Determine common time unit
    units = set(dataset['unit'] for dataset in datasets if dataset['unit'])
    if len(units) > 1:
        print(
            f"‚ö†Ô∏è Warning: Multiple time units detected: {units}. Using first unit.")
    common_unit = datasets[0]['unit'] if datasets else "units"

    # Plot each dataset
    for i, dataset in enumerate(datasets):
        if not dataset['sizes'] or not dataset['times']:
            print(f"‚ö†Ô∏è Skipping empty dataset: {dataset['label']}")
            continue

        # Sort data by sample size to ensure proper line plotting
        sorted_data = sorted(zip(dataset['sizes'], dataset['times']))
        sizes_sorted, times_sorted = zip(
            *sorted_data) if sorted_data else ([], [])

        color_index = i % len(COLOR_PALETTE)
        color = COLOR_PALETTE[color_index]

        # Create label with filename and unit if different
        label = dataset['label']
        if dataset['unit'] != common_unit:
            label = f"{label} ({dataset['unit']})"

        ax.plot(
            sizes_sorted,
            times_sorted,
            'o-',
            color=color,
            linewidth=2.5,
            markersize=6,
            markerfacecolor=color,
            markeredgecolor='#FFFFFF',
            markeredgewidth=1,
            label=label
        )

    # Axes and style configuration
    ax.set_xlabel('Sample Size', fontsize=12, fontweight='bold')
    ax.set_ylabel(f'Time ({common_unit})', fontsize=12, fontweight='bold')
    ax.set_title(
        'Execution Time vs Sample Size',
        fontsize=14,
        fontweight='bold',
        pad=20
    )

    # Grid style
    ax.grid(True, linestyle='-', alpha=0.3)
    ax.set_axisbelow(True)  # Grid behind the data

    # Legend and layout
    ax.legend(framealpha=0.9, loc='best')
    fig.tight_layout()

    # Save with a black background
    try:
        fig.savefig(
            output_path,
            facecolor='#0A0A0A',
            edgecolor='none',
            bbox_inches='tight',
            dpi=300
        )
        print(f"‚úÖ Plot saved to {output_path}")
    except Exception as e:
        print(f"‚ùå Error saving plot: {e}")
        return

    # Show or close
    if os.getenv('SUPPRESS_PLOT_DISPLAY'):
        plt.close(fig)
    else:
        plt.show()


def main() -> None:
    """Main function of the script."""
    if len(sys.argv) < 2:
        print("Usage: python plot.py <data_file1> [<data_file2> ...]")
        print("Supported formats: .csv, .json")
        print("Example: python plot.py data/report1.csv data/report2.json")
        print("Example: python plot.py results/*.csv")
        sys.exit(1)

    file_paths = [Path(arg) for arg in sys.argv[1:]]
    valid_datasets = []

    # Process each file
    for file_path in file_paths:
        # Validations
        if not file_path.exists():
            print(f"‚ùå Error: File '{file_path}' not found")
            continue

        if file_path.suffix.lower() not in {'.csv', '.json'}:
            print(
                f"‚ùå Error: Unsupported file format for '{file_path}'. Use .csv or .json")
            continue

        try:
            print(f"üìñ Reading data from: {file_path}")
            sizes, times, unit, filename = read_data(file_path)

            if validate_data(sizes, times, file_path.name):
                valid_datasets.append({
                    'sizes': sizes,
                    'times': times,
                    'unit': unit,
                    'label': filename
                })
                print(
                    f"‚úÖ Successfully loaded {len(sizes)} data points from {file_path.name}")

        except (ValueError, json.JSONDecodeError, OSError) as e:
            print(f"‚ùå Error processing file '{file_path}': {e}")
        except Exception as e:
            print(f"‚ùå Unexpected error processing file '{file_path}': {e}")

    # Check if we have any valid data to plot
    if not valid_datasets:
        print("‚ùå Error: No valid data files to plot")
        sys.exit(1)

    total_points = sum(len(dataset['sizes']) for dataset in valid_datasets)
    print(f"üìä Total datasets to plot: {len(valid_datasets)}")
    print(f"üìä Total data points: {total_points}")

    # Generate output filename based on input files
    if len(valid_datasets) == 1:
        output_path = file_paths[0].with_suffix('.png')
    else:
        # For multiple files, create a combined name
        base_name = "_".join(dataset['label']
                             for dataset in valid_datasets[:3])
        if len(valid_datasets) > 3:
            base_name += f"_and_{len(valid_datasets) - 3}_more"
        output_path = file_paths[0].parent / f"{base_name}_comparison.png"

    try:
        plot_metrics(valid_datasets, output_path)
    except Exception as e:
        print(f"‚ùå Error during plotting: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()
